{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c78bdef8",
   "metadata": {},
   "source": [
    "# motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eca883",
   "metadata": {},
   "source": [
    "## Preprogress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c13cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "folder_path = 'Path/to/inference'\n",
    "folder_name = \"inference_folder\"\n",
    "model_name = folder_name.split('_')[-1]\n",
    "kind_exp = folder_name.split('_')[-2]\n",
    "\n",
    "file_paths = glob.glob(folder_path + folder_name + \"/result_index_*.csv\")\n",
    "\n",
    "def extract_index(path):\n",
    "    match = re.search(r\"result_index_(\\d+)_\", os.path.basename(path))\n",
    "    return int(match.group(1)) if match else 1e9   #\n",
    "file_paths = sorted(file_paths, key=extract_index)\n",
    "\n",
    "\n",
    "merged_df = pd.concat([pd.read_csv(fp) for fp in file_paths], ignore_index=True)\n",
    "\n",
    "profile_columns = merged_df.columns[:5]\n",
    "res_columns = merged_df.columns[list(range(5,35,2))]\n",
    "rea_columns = merged_df.columns[list(range(6,36,2))]\n",
    "\n",
    "print(merged_df.shape) \n",
    "merged_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_result(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    filt_str = re.sub(r'[^\\u4e00-\\u9fa5a-zA-Z0-9=()（）]', '', text)\n",
    "    \n",
    "    match = re.search(r'选择(.*?)$', filt_str) \n",
    "    if match:\n",
    "        choice = match.group(1)\n",
    "\n",
    "    else:\n",
    "        print(\"choice error\")\n",
    "        choice = ''\n",
    "    \n",
    "    return choice\n",
    "\n",
    "\n",
    "def process_text_series(text_serires,both_flag):\n",
    "    choice_series, thinking_answer_serires = [],[]\n",
    "    for text_item in enumerate(text_serires):\n",
    "        if both_flag == 1: \n",
    "            # _,choice,thinking_answer = process_text(text_item[1])\n",
    "            pass\n",
    "        elif both_flag==0:\n",
    "            choice = process_text_result(text_item[1])\n",
    "            thinking_answer = None\n",
    "        elif both_flag == 2: \n",
    "            # _,choice,thinking_answer = process_text_trained(text_item[1])\n",
    "            pass\n",
    "        choice_series.append(choice)\n",
    "        thinking_answer_serires.append(thinking_answer)\n",
    "\n",
    "    return choice_series,thinking_answer_serires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "choice_columns,think_columns = [],[]\n",
    "for question_id, question_column in enumerate(res_columns):\n",
    "    new_col_name = str(question_id)+'_chocice'\n",
    "    \n",
    "    choice_columns.append(new_col_name)        \n",
    "    choice, thinking_answer = process_text_series(merged_df[question_column],0)\n",
    "    merged_df[new_col_name] = choice\n",
    "\n",
    "    if kind_exp != 'direct': \n",
    "        new_col_name_think = str(question_id) + '_thinking'\n",
    "        think_columns.append(new_col_name_think)\n",
    "        merged_df[new_col_name_think] = merged_df.iloc[:,int(question_column)+1]\n",
    "\n",
    "print(merged_df.shape)\n",
    "\n",
    "merged_df.to_csv(folder_path + folder_name + \"/merged_result.csv\", index=False)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "question_path = './Code/Data/SBR-Question-list.json'\n",
    "with open(question_path, 'r', encoding='utf-8') as file:\n",
    "    question_dict = json.load(file)\n",
    "question_list = []\n",
    "for topic,topic_value in question_dict.items():\n",
    "    for questin_id,question_value in topic_value.items():\n",
    "        question_list.append(question_value['question'])\n",
    "\n",
    "for question_id,question in enumerate(question_list):\n",
    "    option_len = len(question['option'])\n",
    "    option_to_num = {option.replace('，', ''): idx for idx, option in enumerate(question['option'])}\n",
    "    if question_id in [6,7,8]:\n",
    "        # 道德困境单独加\n",
    "        option_to_num['yes']=0\n",
    "        option_to_num['no']=1\n",
    "    if question_id == 9:\n",
    "        new_dict = option_to_num.copy()\n",
    "        for key, value in option_to_num.items():\n",
    "            number = key.split('=')[1]  \n",
    "            new_dict[number] = value\n",
    "        option_to_num = new_dict.copy()\n",
    "    \n",
    "\n",
    "    def custom_map(value):\n",
    "        if not isinstance(value, str):  \n",
    "            return value  \n",
    "        for key, num in option_to_num.items():\n",
    "            if key in value:\n",
    "                return num\n",
    "        return np.nan  \n",
    "    \n",
    "    \n",
    "    merged_df[choice_columns[question_id]] = merged_df[choice_columns[question_id]].apply(custom_map)\n",
    "    \n",
    "    merged_df[choice_columns[question_id]] = merged_df[choice_columns[question_id]] / (option_len - 1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d12ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if kind_exp != 'direct':\n",
    "    missing_rows = merged_df.loc[:,choice_columns][merged_df.loc[:,choice_columns].isnull().any(axis=1)]\n",
    "    missing_count_per_row = missing_rows.isnull().sum(axis=1)\n",
    "    print(missing_count_per_row)\n",
    "    total_missing_count = missing_count_per_row.sum()\n",
    "    print(total_missing_count)\n",
    "else :\n",
    "    missing_rows = merged_df[merged_df.isnull().any(axis=1)]\n",
    "    missing_count_per_row = missing_rows.isnull().sum(axis=1)-15\n",
    "    print(missing_count_per_row[missing_count_per_row>0])\n",
    "    total_missing_count = missing_count_per_row.sum()\n",
    "    print(total_missing_count)\n",
    "\n",
    "missing_positions = merged_df.isnull()\n",
    "merged_df.to_csv(folder_path + folder_name + \"/merged_choicenum_result.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455293f",
   "metadata": {},
   "source": [
    "## cal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2887820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "question_path = './Code/Data/SBR-Question-list.json'\n",
    "with open(question_path, 'r', encoding='utf-8') as file:\n",
    "    question_dict = json.load(file)\n",
    "    \n",
    "question_list = []\n",
    "for topic,topic_value in question_dict.items():\n",
    "    for questin_id,question_value in topic_value.items():\n",
    "        question_list.append(question_value['question'])\n",
    "\n",
    "option_num_list = [len(list(item['option'])) for item in question_list]\n",
    "max_entropy_list = [np.log2(n) for n in option_num_list]\n",
    "\n",
    "all_possible_values_list = []\n",
    "\n",
    "for question_id,question in enumerate(question_list):\n",
    "    option_len = len(question['option'])\n",
    "    all_possible_values_list.append([i/(option_len-1) for i in range(option_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def load_data(result_path):\n",
    "    profile_columns = ['0','1','2','3','4']\n",
    "    df = pd.read_csv(result_path+'/merged_choicenum_result.csv')\n",
    "    for col in profile_columns:\n",
    "        df[col] = df[col].fillna(-1).astype(int) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f08f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def calculate_entropy(series):\n",
    "    series = series.dropna()\n",
    "    counts = series.value_counts()\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    if entropy==-0.00:\n",
    "        entropy = 0\n",
    "    return entropy\n",
    "\n",
    "def calculate_rmse(series,human_series): \n",
    "    if len(series) != len(human_series):\n",
    "        raise ValueError(\"different length\")\n",
    "   \n",
    "    mask = ~np.isnan(series) & ~np.isnan(human_series)  \n",
    "    if not np.any(mask): \n",
    "        print(\"no data\")\n",
    "        return np.nan\n",
    "    series = series[mask]\n",
    "    human_series = human_series[mask]\n",
    "\n",
    "    squared_diff = (series - human_series) ** 2\n",
    "    rmse = np.sqrt(np.mean(squared_diff))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def Cal_enr_kl_group(df,non_human,human_df):\n",
    "  \n",
    "    choice_columns = [str(i)+'_chocice' for i in range(0,15)]\n",
    "    result_dict = {'entropies':{},'rmse':{}}\n",
    "\n",
    "\n",
    "    for i,choice_column in enumerate(choice_columns):\n",
    "        temp_en = calculate_entropy(df[choice_column])/max_entropy_list[i]\n",
    "        result_dict['entropies'][i] = temp_en\n",
    "    average_en = np.nanmean(list(result_dict['entropies'].values()))\n",
    "    result_dict['entropies']['average'] = average_en\n",
    "\n",
    "    for i,choice_column in enumerate(choice_columns):\n",
    "        temp_dif = calculate_rmse(df[choice_column],human_df[choice_column])\n",
    "        result_dict['rmse'][i] = temp_dif\n",
    "    average_rmse = np.nanmean(list(result_dict['rmse'].values()))\n",
    "    result_dict['rmse']['average'] = average_rmse\n",
    "    \n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_en_kl(model_name,result_dict,save_path,non_human):\n",
    "    with open(save_path+'/motivation_result.json', \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result_dict, f, ensure_ascii=False, indent=2)\n",
    "    print(f'model：{model_name} \\n en:{result_dict[\"entropies\"][\"average\"]:.3f}\\n recall:{result_dict[\"recall\"]:.3f}\\n acc:{1-result_dict[\"rmse\"][\"average\"]:.3f}')\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc21762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "profile_columns = ['0','1','2','3','4']\n",
    "choice_columns = [str(i)+'_chocice' for i in range(0,15)]\n",
    "human_df = pd.read_csv(\"Path/To/Humandata\")\n",
    "human_df['all'] = np.ones(human_df.shape[0])\n",
    "\n",
    "BASE_FOLDER_PATH= 'Path/to/inference'\n",
    "BASE_MODEL_NAME= ['inference_folder',] \n",
    "for base_model in BASE_MODEL_NAME:\n",
    "    base_result_path = BASE_FOLDER_PATH+base_model\n",
    "    base_df = load_data(base_result_path)\n",
    "    direct_result = Cal_enr_kl_group(base_df,True,human_df) \n",
    "    result_csv = save_en_kl(base_model,direct_result,base_result_path,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
